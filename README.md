# Realtime-Data-Streaming
# ---
Program was implemented using Python, Random Name API, Airflow, Kafka, Spark and MongoDB. 

# ---
## Architecture
Overview:
    - A Random Name API integration is utilized to fetch data for processing and subsequent orchestration via Apache Airflow.
    - Kafka acts as a streaming platform, ingesting data and facilitating communication between pipeline components.
    - MongoDB serves as a persistent data store for personal information, enabling later analysis.

## ---
### Airflow

## ---
### Kafka

## ---
### Spark

## ---
### MongoDB

